import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime

def fetch_html(url):
    """Fetch the HTML content from the given URL."""
    try:
        response = requests.get(url)
        response.raise_for_status()  # Will raise an exception for non-200 responses
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"Error fetching the URL: {e}")
        return None

def parse_table(soup):
    """Parse the table data from the BeautifulSoup object."""
    table = soup.find("table", class_="sc-936354b2-3 tLXcG cmc-table")
    if not table:
        print("Error: Table not found.")
        return None, None

    # Extract headers (titles), skip the first two and last column titles
    titles = [tag.text.strip() for tag in table.find_all("th")]
    filtered_titles = titles[2:-1]
    
    rows = table.find_all("tr")[1:]  # Skip the header row
    data = []
    
    for row in rows:
        cells = row.find_all("td")
        if len(cells) > 0:
            # Extract relevant data and handle missing values
            filtered_row = [cell.text.strip() if cell.text.strip() != '' else 'N/A' for cell in cells[2:-1]]
            data.append(filtered_row)
    
    return filtered_titles, data

def main():
    url = "https://coinmarketcap.com/"
    
    # Fetch and parse HTML
    html_content = fetch_html(url)
    if not html_content:
        return
    
    soup = BeautifulSoup(html_content, "lxml")
    
    # Parse the table and extract data
    titles, data = parse_table(soup)
    if not data:
        return
    
    # Add the current date and time as an extra column
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    titles.append("Scraped Time")  # Add new title for the timestamp
    
    # Add the timestamp to each row
    for row in data:
        row.append(current_datetime)
    
    # Create DataFrame
    df = pd.DataFrame(data, columns=titles)
    
    # Print the first 10 rows for confirmation
    print("First 10 rows of DataFrame:")
    print(df.head(10))
    
    # Optionally, save the data to a CSV file (for simplicity, not using Excel here)
    file_name = 'coinmarketcap_with_time.csv'
    df.to_csv(file_name, index=False)
    print(f"DataFrame saved to {file_name}")

if __name__ == "__main__":
    main()
